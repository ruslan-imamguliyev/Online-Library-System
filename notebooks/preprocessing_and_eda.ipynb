{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b06d523f",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab6015",
   "metadata": {},
   "source": [
    "### Getting Ready"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e072ecd8",
   "metadata": {},
   "source": [
    "Importing libraries and setting some variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c806e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import glob\n",
    "\n",
    "RATING_THRESHOLD = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30ee2ea",
   "metadata": {},
   "source": [
    "Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4458ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    df = df.copy()\n",
    "    # Dropping missing values in essential columns\n",
    "    df.dropna(subset=['author', 'summary', 'genres'], inplace=True)\n",
    "\n",
    "    # Dropping unnecessary columns\n",
    "    df.drop(columns=['about_author', 'community_reviews', 'kindle_price', 'num_reviews', 'id'], inplace=True)\n",
    "\n",
    "    # Converting 'author' from string representation of list to actual list and extracting the first author\n",
    "    df['author'] = df['author'].apply(lambda x: ast.literal_eval(x)[0])\n",
    "\n",
    "    # There are some authors with no name or unknown names, we can filter them out\n",
    "    na_authors = ['Anonymous', 'Unknown', 'Various']\n",
    "    df = df[~df['author'].isin(na_authors)]\n",
    "\n",
    "    # Dropping rows with missing or insignificant summaries\n",
    "    df = df[~df['summary'].str.len() < 75]\n",
    "\n",
    "    # Converting 'genres' from string representation of list to actual list and joining them into a single string\n",
    "    df['genres'] = df['genres'].apply(lambda x: \" \".join(ast.literal_eval(x)))\n",
    "\n",
    "    # Utilizing 'w_rating' (weighted rating) that makes 'star_rating' more valuable when more people ('num_ratings') do rate it\n",
    "    # Also setting a threshold for 'num_ratings' to filter out books with too few ratings\n",
    "    df = df[df['num_ratings'] > RATING_THRESHOLD]\n",
    "    df['w_rating'] = (df['num_ratings'] / (df['num_ratings'] + RATING_THRESHOLD) * df['star_rating'] +\n",
    "                  RATING_THRESHOLD / (df['num_ratings'] + RATING_THRESHOLD) * df['star_rating'].mean()).round(2)\n",
    "\n",
    "    # Adding a new column 'tags' that combines genres, author, and summary for better searchability\n",
    "    df['tags'] = df['genres'].str.lower() + ' ' \\\n",
    "        + df['author'].str.lower().replace(' ', '') + ' ' \\\n",
    "        + df['summary'].str.lower()\n",
    "    \n",
    "    # Clean up punctuation\n",
    "    df['tags'] = df['tags'].str.replace(r'[^\\w\\s]', '', regex=True).str.replace(r'\\s+', ' ', regex=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee38773",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing stage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61197dae",
   "metadata": {},
   "source": [
    "Detecting all `.parquet` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad6db6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_files = glob.glob('../datasets/*.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02066124",
   "metadata": {},
   "source": [
    "Preprocessing all `.parquet` files and appending to the `result` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22346984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ../datasets\\0000.parquet\n",
      "Processing file: ../datasets\\0001.parquet\n",
      "Processing file: ../datasets\\0002.parquet\n",
      "Processing file: ../datasets\\0003.parquet\n",
      "Processing file: ../datasets\\0004.parquet\n",
      "Processing file: ../datasets\\0005.parquet\n",
      "Processing file: ../datasets\\0006.parquet\n",
      "Processing file: ../datasets\\0007.parquet\n",
      "Processing file: ../datasets\\0008.parquet\n",
      "Processing file: ../datasets\\0009.parquet\n"
     ]
    }
   ],
   "source": [
    "# result = pd.DataFrame()\n",
    "# for file in parquet_files:\n",
    "#     print(f\"Processing file: {file}\")\n",
    "#     result = pd.concat([result, pre(pd.read_parquet(file))], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c59a2e8",
   "metadata": {},
   "source": [
    "Resetting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eacbabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ac864e",
   "metadata": {},
   "source": [
    "Saving the `result` DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff96a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_parquet('../datasets/processed_books.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdb77fc",
   "metadata": {},
   "source": [
    "### 2. Data Analysis with the whole processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de95d901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
